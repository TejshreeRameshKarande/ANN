{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN+ZJYQ9sykK1EzXufSGBPb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TejshreeRameshKarande/ANN/blob/main/back_propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtW99fHJAHJp",
        "outputId": "49252ab5-fca7-44c0-be83-bdf4ce96319a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0, Error: 0.3524531500032219\n",
            "Epoch 1000, Error: 0.0011269068429650378\n",
            "Epoch 2000, Error: 0.00018652092451999812\n",
            "Epoch 3000, Error: 7.069586861231631e-05\n",
            "Epoch 4000, Error: 3.6398578489196256e-05\n",
            "Epoch 5000, Error: 2.1985456010687314e-05\n",
            "Epoch 6000, Error: 1.4646914722719431e-05\n",
            "Epoch 7000, Error: 1.0426075365865204e-05\n",
            "Epoch 8000, Error: 7.784458085929007e-06\n",
            "Epoch 9000, Error: 6.025380843583384e-06\n",
            "Final prediction after training: [0.00267914 0.99844493]\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "# Sigmoid activation function\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "# Sigmoid derivative\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "# Initialize the network parameters\n",
        "# Inputs\n",
        "x1 = np.array([0, 1])\n",
        "x2 = np.array([0, 1])\n",
        "\n",
        "# Weights (randomly initialized)\n",
        "w1 = np.random.randn()\n",
        "w2 = np.random.randn()\n",
        "w3 = np.random.randn()\n",
        "w4 = np.random.randn()\n",
        "\n",
        "# Bias terms (randomly initialized)\n",
        "b1 = np.random.randn()\n",
        "b2 = np.random.randn()\n",
        "\n",
        "# Actual output for calculating error\n",
        "y_actual = np.array([0, 1])\n",
        "\n",
        "# Learning rate\n",
        "learning_rate = 0.1\n",
        "\n",
        "# Number of epochs\n",
        "epochs = 10000\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(epochs):\n",
        "    # Forward pass\n",
        "    h = sigmoid(w1*x1 + w2*x2 + b1)  # Hidden layer output\n",
        "    y_pred = sigmoid(w3*h + w4*h + b2)  # Output layer prediction\n",
        "\n",
        "    # Calculate the error\n",
        "    error = 0.5 * np.sum((y_actual - y_pred)**2)\n",
        "\n",
        "    # Backward pass\n",
        "    # Compute gradients for each weight using the chain rule\n",
        "    dE_dypred = y_pred - y_actual\n",
        "    dypred_dw3 = h\n",
        "    dypred_dh = w3 * sigmoid_derivative(h) + w4 * sigmoid_derivative(h)  # derivative of output layer with respect to hidden layer\n",
        "    dE_dh = dE_dypred * dypred_dh\n",
        "\n",
        "    # Gradients for weights and bias\n",
        "    dE_dw3 = np.sum(dE_dypred * dypred_dw3)\n",
        "    dE_dw4 = np.sum(dE_dypred * dypred_dw3)\n",
        "    dE_db2 = np.sum(dE_dypred)\n",
        "\n",
        "    dE_dh = dE_dypred * sigmoid_derivative(h)\n",
        "    dE_dw1 = np.sum(dE_dh * x1)\n",
        "    dE_dw2 = np.sum(dE_dh * x2)\n",
        "    dE_db1 = np.sum(dE_dh)\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    w1 -= learning_rate * dE_dw1\n",
        "    w2 -= learning_rate * dE_dw2\n",
        "    w3 -= learning_rate * dE_dw3\n",
        "    w4 -= learning_rate * dE_dw4\n",
        "    b1 -= learning_rate * dE_db1\n",
        "    b2 -= learning_rate * dE_db2\n",
        "\n",
        "    # Print the error every 1000 epochs\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}, Error: {error}\")\n",
        "\n",
        "# Final prediction after training\n",
        "print(\"Final prediction after training:\", y_pred)\n",
        "\n"
      ]
    }
  ]
}